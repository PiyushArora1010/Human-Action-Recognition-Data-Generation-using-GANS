{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames =80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import shutil\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "mypath = '../Data/numpy_skeletons/'\n",
    "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.load(mypath + onlyfiles[0],allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_name\n",
      "nbodys\n",
      "njoints\n",
      "skel_body0\n",
      "rgb_body0\n",
      "depth_body0\n"
     ]
    }
   ],
   "source": [
    "for i in temp:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56579/56579 [01:21<00:00, 694.98it/s]\n"
     ]
    }
   ],
   "source": [
    "Data = []\n",
    "labels = []\n",
    "for file in tqdm(onlyfiles):\n",
    "    labels.append(int(file.split('.')[0][-3:]))\n",
    "    temp = np.load(mypath + file,allow_pickle=True).item()\n",
    "    frameTemp = temp['skel_body0'].shape[0]\n",
    "    framesSelected = [i for i in range(frameTemp)]\n",
    "    framesSelected = framesSelected[:frames]\n",
    "    while len(framesSelected) < frames:\n",
    "        random = np.random.randint(0 , frameTemp)\n",
    "        framesSelected.append(random)\n",
    "    framesSelected = sorted(framesSelected)\n",
    "    temp = temp['skel_body0'][framesSelected]\n",
    "    Data.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = np.array(Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data = np.transpose(Data, (0,3,1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2bb7f4f6190>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(Data[0][1][:,0],Data[0][1][:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_data_z = np.max(Data[:,2,:,:])\n",
    "min_data_z = np.min(Data[:,2,:,:])\n",
    "range_z = max_data_z - min_data_z\n",
    "Data[:,2,:,:] = (Data[:,2,:,:] - min_data_z)/range_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_data_y = np.max(Data[:,1:,:])\n",
    "min_data_y = np.min(Data[:,1:,:])\n",
    "range_y = max_data_y - min_data_y\n",
    "Data[:,1,:,:] = (Data[:,1,:,:] - min_data_y)/range_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_data_x = np.max(Data[:,0,:,:])\n",
    "min_data_x = np.min(Data[:,0,:,:])\n",
    "range_x = max_data_x - min_data_x\n",
    "Data[:,0,:,:] = (Data[:,0,:,:] - min_data_x)/range_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = Data - 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(labels).astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = Data [ labels < 10 ]\n",
    "labels = labels [labels < 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_torch = torch.from_numpy(Data.astype('float32'))\n",
    "y = torch.from_numpy(labels.astype('int32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self,imgs,labels):\n",
    "        self.imgs = imgs\n",
    "        self.labels = labels\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.imgs[idx], self.labels[idx]\n",
    "\n",
    "dataset = CustomDataset(Data_torch, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_size=256,\n",
    "    shuffle=True,\n",
    "    drop_last = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(dataloader, 'dataloader_NTU.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\ASUS/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "featureExtractor = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Extractor Downloaded\n"
     ]
    }
   ],
   "source": [
    "# model = models.resnet152(pretrained=True)\n",
    "featureExtractor = torch.nn.Sequential(*(list(featureExtractor.children())[:-1]))\n",
    "featureExtractor.forward(Data_torch[0:10]).size()\n",
    "featureExtractor.eval()\n",
    "print(\"Feature Extractor Downloaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_and_cov(Data_):\n",
    "    tempData = featureExtractor(Data_)\n",
    "    tempData = tempData.view(-1, 512)\n",
    "    meanData = torch.mean(tempData, dim = 0)\n",
    "    covData = torch.cov(torch.t(tempData))\n",
    "    return meanData, covData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "del Data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fid(realData, generated_images):\n",
    "    mean_o,cov_o = mean_and_cov(realData)\n",
    "    mean_g,cov_g = mean_and_cov(generated_images)\n",
    "\n",
    "    ## || u1 - u2 || ^ 2\n",
    "    mean_diff = torch.sum((mean_o - mean_g)**2)\n",
    "    \n",
    "    ## Trace of matrix\n",
    "    covMean = torch.sqrt( cov_o.to(torch.cfloat) @ cov_g.to(torch.cfloat) ).real\n",
    "\n",
    "    return mean_diff + torch.trace( cov_o + cov_g - 2 * covMean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.input = nn.Sequential(\n",
    "            nn.Conv2d(4, 64, 3, 1, 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True))\n",
    "        self.embed = nn.Embedding(60 , 25 * frames)\n",
    "        self.hiddenLayers = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, 3, 1, 1),\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Conv2d(128,256,3,1,1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True)    \n",
    "        )\n",
    "        self.fc = nn.Linear(640000, 512)\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Linear(512,1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x, label):\n",
    "        label_embed = self.embed(label)\n",
    "        label_embed = label_embed.view(label_embed.size(0),1,100,25)\n",
    "        finalInput = torch.cat([x, label_embed], dim=1)\n",
    "        finalInput = self.input(finalInput)\n",
    "        finalInput = self.hiddenLayers(finalInput)\n",
    "        finalInput = finalInput.view(finalInput.size(0),-1)\n",
    "        finalInput = self.fc(finalInput)\n",
    "        finalInput = self.output(finalInput)\n",
    "        return finalInput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(60, 100)\n",
    "        self.input = nn.Sequential(\n",
    "            nn.ConvTranspose2d(200, 512, 4, 1, 0),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.hiddenlayers = nn.Sequential(\n",
    "            nn.ConvTranspose2d(512, 256, 4, 2, 1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(), \n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),  \n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),         \n",
    "            nn.ConvTranspose2d(64, 16, 4 , 2, 1) \n",
    "        )\n",
    "        self.layer = nn.Linear(65536, 7500)\n",
    "        self.output = nn.Tanh()\n",
    "    def forward(self,x, label):\n",
    "        labelEmb = self.embed(label)\n",
    "        labelEmb = labelEmb.view(labelEmb.size(0), 100, 1, 1)\n",
    "        finalInput = torch.cat([x, labelEmb], dim = 1)\n",
    "        finalInput = self.input(finalInput)\n",
    "        finalInput = self.hiddenlayers(finalInput)\n",
    "        finalInput = finalInput.view(finalInput.size(0),-1)\n",
    "        finalInput = self.layer(finalInput)\n",
    "        \n",
    "        finalInput = finalInput.view(finalInput.size(0), 3, 100, 25)\n",
    "        return self.output(finalInput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Models\n",
    "'''\n",
    "generator = Generator().to(device)\n",
    "discriminator = Discriminator().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Losses\n",
    "'''\n",
    "adversarial_loss = nn.BCELoss()\n",
    "adversarial_loss = adversarial_loss.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_G = torch.optim.Adam(generator.parameters(),lr=0.00002, betas=(0.5, 0.999) )\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(),lr=0.00002, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "\n",
    "epochs = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in tqdm(range(epochs)):\n",
    "    gLoss = -1\n",
    "    dLoss = -1\n",
    "    f1score = float(\"inf\")\n",
    "    for index, (data, label) in enumerate(dataloader):\n",
    "\n",
    "        valid = Variable(Tensor(data.size(0), 1).fill_(1.0), requires_grad=False)\n",
    "        fake = Variable(Tensor(data.size(0), 1).fill_(0.0), requires_grad=False)\n",
    "\n",
    "        label = label.to(device)\n",
    "\n",
    "        real_imgs = Variable(data.type(Tensor))\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        z = Variable(Tensor(np.random.normal(0, 1, (data.shape[0], 100,1,1))))\n",
    "\n",
    "        gen_imgs = generator(z,label)\n",
    "\n",
    "        gen_imgs = gen_imgs.to(device)\n",
    "\n",
    "        g_loss = adversarial_loss(discriminator(gen_imgs,label), valid)\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        real_loss = adversarial_loss(discriminator(real_imgs,label), valid)\n",
    "        fake_loss = adversarial_loss(discriminator(gen_imgs.detach(),label), fake)\n",
    "\n",
    "        d_loss = (real_loss + fake_loss)\n",
    "\n",
    "        d_loss.backward()\n",
    "\n",
    "        optimizer_D.step()\n",
    "\n",
    "        gLoss = g_loss.item()\n",
    "        dLoss = d_loss.item()\n",
    "\n",
    "        f1Temp = -(gLoss * dLoss) / (gLoss + dLoss)\n",
    "        if f1Temp < f1score:\n",
    "            f1score = f1Temp\n",
    "            torch.save(generator.state_dict(),'Models/generator.pth')\n",
    "    if (epoch+1)%50 == 0:\n",
    "        print('gLoss ==>',round(gLoss,4))\n",
    "        print(\"dLoss ==>\",round(dLoss,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = generator(torch.randn(1, 100 , 1 , 1).to(device), torch.tensor([[1]]).to(device))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "43d067841d78aac7fa29634787a4d238b2cfa1e9a088c54a4c88156792dfd315"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('machineLearning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
