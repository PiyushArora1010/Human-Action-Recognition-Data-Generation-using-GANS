{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tgan'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ASUS\\Desktop\\Research Work\\France\\Codes\\cDCGAN.ipynb Cell 1'\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ASUS/Desktop/Research%20Work/France/Codes/cDCGAN.ipynb#ch0000000?line=10'>11</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtqdm\u001b[39;00m \u001b[39mimport\u001b[39;00m tqdm\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ASUS/Desktop/Research%20Work/France/Codes/cDCGAN.ipynb#ch0000000?line=11'>12</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchsummary\u001b[39;00m \u001b[39mimport\u001b[39;00m summary\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/ASUS/Desktop/Research%20Work/France/Codes/cDCGAN.ipynb#ch0000000?line=12'>13</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtgan\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel\u001b[39;00m \u001b[39mimport\u001b[39;00m TGANModel\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tgan'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from data_for_gan import data_for_gan\n",
    "from tqdm import tqdm\n",
    "from torchsummary import summary\n",
    "from tgan.model import TGANModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0 2.0 3.0 4.0 5.0 6.0 7.0 8.0 9.0]\n"
     ]
    }
   ],
   "source": [
    "dataset,y,df = data_for_gan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torch.from_numpy(dataset.astype('float32'))\n",
    "y = torch.from_numpy(y.astype('int32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity no.</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f38</th>\n",
       "      <th>f39</th>\n",
       "      <th>f40</th>\n",
       "      <th>f41</th>\n",
       "      <th>f42</th>\n",
       "      <th>f43</th>\n",
       "      <th>f44</th>\n",
       "      <th>f45</th>\n",
       "      <th>Action</th>\n",
       "      <th>Human</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-222.737122</td>\n",
       "      <td>540.995422</td>\n",
       "      <td>2832.409912</td>\n",
       "      <td>-233.136169</td>\n",
       "      <td>288.886017</td>\n",
       "      <td>2808.759277</td>\n",
       "      <td>-226.604401</td>\n",
       "      <td>85.114182</td>\n",
       "      <td>2796.978516</td>\n",
       "      <td>...</td>\n",
       "      <td>-114.83284</td>\n",
       "      <td>2771.922119</td>\n",
       "      <td>-78.613121</td>\n",
       "      <td>-542.027649</td>\n",
       "      <td>2771.436035</td>\n",
       "      <td>-18.19173</td>\n",
       "      <td>-930.296204</td>\n",
       "      <td>2827.437988</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-222.75412</td>\n",
       "      <td>541.178589</td>\n",
       "      <td>2830.108398</td>\n",
       "      <td>-231.847168</td>\n",
       "      <td>288.444183</td>\n",
       "      <td>2809.476074</td>\n",
       "      <td>-225.781021</td>\n",
       "      <td>84.746086</td>\n",
       "      <td>2797.4104</td>\n",
       "      <td>...</td>\n",
       "      <td>-115.326927</td>\n",
       "      <td>2772.170166</td>\n",
       "      <td>-77.628181</td>\n",
       "      <td>-544.114624</td>\n",
       "      <td>2772.243164</td>\n",
       "      <td>-16.370182</td>\n",
       "      <td>-935.252625</td>\n",
       "      <td>2825.971436</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-221.253021</td>\n",
       "      <td>542.361633</td>\n",
       "      <td>2828.212402</td>\n",
       "      <td>-231.197784</td>\n",
       "      <td>286.976593</td>\n",
       "      <td>2810.302002</td>\n",
       "      <td>-225.112366</td>\n",
       "      <td>84.134377</td>\n",
       "      <td>2798.335205</td>\n",
       "      <td>...</td>\n",
       "      <td>-115.031052</td>\n",
       "      <td>2772.760986</td>\n",
       "      <td>-76.57428</td>\n",
       "      <td>-543.925232</td>\n",
       "      <td>2773.098633</td>\n",
       "      <td>-16.996519</td>\n",
       "      <td>-935.505066</td>\n",
       "      <td>2828.508057</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-220.483627</td>\n",
       "      <td>542.407715</td>\n",
       "      <td>2827.968262</td>\n",
       "      <td>-230.249573</td>\n",
       "      <td>285.834198</td>\n",
       "      <td>2810.092773</td>\n",
       "      <td>-224.584686</td>\n",
       "      <td>83.829437</td>\n",
       "      <td>2798.306396</td>\n",
       "      <td>...</td>\n",
       "      <td>-114.668465</td>\n",
       "      <td>2772.653076</td>\n",
       "      <td>-75.057556</td>\n",
       "      <td>-544.48761</td>\n",
       "      <td>2775.745117</td>\n",
       "      <td>-16.88364</td>\n",
       "      <td>-937.05603</td>\n",
       "      <td>2833.645752</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-221.115891</td>\n",
       "      <td>542.176758</td>\n",
       "      <td>2829.080566</td>\n",
       "      <td>-230.501373</td>\n",
       "      <td>285.660583</td>\n",
       "      <td>2810.690918</td>\n",
       "      <td>-224.820831</td>\n",
       "      <td>83.872169</td>\n",
       "      <td>2798.683105</td>\n",
       "      <td>...</td>\n",
       "      <td>-114.363319</td>\n",
       "      <td>2772.71167</td>\n",
       "      <td>-74.918259</td>\n",
       "      <td>-544.191223</td>\n",
       "      <td>2775.963623</td>\n",
       "      <td>-16.241182</td>\n",
       "      <td>-935.5224</td>\n",
       "      <td>2832.526611</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6445</th>\n",
       "      <td>215.0</td>\n",
       "      <td>-251.36673</td>\n",
       "      <td>615.119385</td>\n",
       "      <td>2651.102295</td>\n",
       "      <td>-213.644806</td>\n",
       "      <td>366.986511</td>\n",
       "      <td>2745.237793</td>\n",
       "      <td>-207.447266</td>\n",
       "      <td>156.703217</td>\n",
       "      <td>2786.439209</td>\n",
       "      <td>...</td>\n",
       "      <td>-62.636711</td>\n",
       "      <td>2768.670898</td>\n",
       "      <td>-117.46299</td>\n",
       "      <td>-495.449005</td>\n",
       "      <td>2783.337891</td>\n",
       "      <td>-110.195564</td>\n",
       "      <td>-921.249329</td>\n",
       "      <td>2863.574463</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6446</th>\n",
       "      <td>215.0</td>\n",
       "      <td>-251.36673</td>\n",
       "      <td>615.119385</td>\n",
       "      <td>2651.102295</td>\n",
       "      <td>-213.644806</td>\n",
       "      <td>366.986511</td>\n",
       "      <td>2745.237793</td>\n",
       "      <td>-207.447266</td>\n",
       "      <td>156.703217</td>\n",
       "      <td>2786.439209</td>\n",
       "      <td>...</td>\n",
       "      <td>-62.636711</td>\n",
       "      <td>2768.670898</td>\n",
       "      <td>-117.46299</td>\n",
       "      <td>-495.449005</td>\n",
       "      <td>2783.337891</td>\n",
       "      <td>-110.195564</td>\n",
       "      <td>-921.249329</td>\n",
       "      <td>2863.574463</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6447</th>\n",
       "      <td>215.0</td>\n",
       "      <td>-223.757309</td>\n",
       "      <td>636.501526</td>\n",
       "      <td>2682.291016</td>\n",
       "      <td>-198.897583</td>\n",
       "      <td>382.04184</td>\n",
       "      <td>2759.463623</td>\n",
       "      <td>-202.598618</td>\n",
       "      <td>164.404648</td>\n",
       "      <td>2791.465576</td>\n",
       "      <td>...</td>\n",
       "      <td>-62.891205</td>\n",
       "      <td>2767.439941</td>\n",
       "      <td>-114.05262</td>\n",
       "      <td>-498.39682</td>\n",
       "      <td>2785.745605</td>\n",
       "      <td>-107.40934</td>\n",
       "      <td>-923.218323</td>\n",
       "      <td>2864.661865</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6448</th>\n",
       "      <td>215.0</td>\n",
       "      <td>-223.757309</td>\n",
       "      <td>636.501526</td>\n",
       "      <td>2682.291016</td>\n",
       "      <td>-198.897583</td>\n",
       "      <td>382.04184</td>\n",
       "      <td>2759.463623</td>\n",
       "      <td>-202.598618</td>\n",
       "      <td>164.404648</td>\n",
       "      <td>2791.465576</td>\n",
       "      <td>...</td>\n",
       "      <td>-62.891205</td>\n",
       "      <td>2767.439941</td>\n",
       "      <td>-114.05262</td>\n",
       "      <td>-498.39682</td>\n",
       "      <td>2785.745605</td>\n",
       "      <td>-107.40934</td>\n",
       "      <td>-923.218323</td>\n",
       "      <td>2864.661865</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6449</th>\n",
       "      <td>215.0</td>\n",
       "      <td>-198.147232</td>\n",
       "      <td>656.310242</td>\n",
       "      <td>2720.769287</td>\n",
       "      <td>-185.726929</td>\n",
       "      <td>393.947174</td>\n",
       "      <td>2771.234375</td>\n",
       "      <td>-196.037186</td>\n",
       "      <td>171.085327</td>\n",
       "      <td>2796.786621</td>\n",
       "      <td>...</td>\n",
       "      <td>-61.606247</td>\n",
       "      <td>2769.630859</td>\n",
       "      <td>-115.142174</td>\n",
       "      <td>-498.411865</td>\n",
       "      <td>2786.321045</td>\n",
       "      <td>-106.461594</td>\n",
       "      <td>-922.787598</td>\n",
       "      <td>2865.870117</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6450 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     activity no.          f1          f2           f3          f4  \\\n",
       "0             1.0 -222.737122  540.995422  2832.409912 -233.136169   \n",
       "1             1.0  -222.75412  541.178589  2830.108398 -231.847168   \n",
       "2             1.0 -221.253021  542.361633  2828.212402 -231.197784   \n",
       "3             1.0 -220.483627  542.407715  2827.968262 -230.249573   \n",
       "4             1.0 -221.115891  542.176758  2829.080566 -230.501373   \n",
       "...           ...         ...         ...          ...         ...   \n",
       "6445        215.0  -251.36673  615.119385  2651.102295 -213.644806   \n",
       "6446        215.0  -251.36673  615.119385  2651.102295 -213.644806   \n",
       "6447        215.0 -223.757309  636.501526  2682.291016 -198.897583   \n",
       "6448        215.0 -223.757309  636.501526  2682.291016 -198.897583   \n",
       "6449        215.0 -198.147232  656.310242  2720.769287 -185.726929   \n",
       "\n",
       "              f5           f6          f7          f8           f9  ...  \\\n",
       "0     288.886017  2808.759277 -226.604401   85.114182  2796.978516  ...   \n",
       "1     288.444183  2809.476074 -225.781021   84.746086    2797.4104  ...   \n",
       "2     286.976593  2810.302002 -225.112366   84.134377  2798.335205  ...   \n",
       "3     285.834198  2810.092773 -224.584686   83.829437  2798.306396  ...   \n",
       "4     285.660583  2810.690918 -224.820831   83.872169  2798.683105  ...   \n",
       "...          ...          ...         ...         ...          ...  ...   \n",
       "6445  366.986511  2745.237793 -207.447266  156.703217  2786.439209  ...   \n",
       "6446  366.986511  2745.237793 -207.447266  156.703217  2786.439209  ...   \n",
       "6447   382.04184  2759.463623 -202.598618  164.404648  2791.465576  ...   \n",
       "6448   382.04184  2759.463623 -202.598618  164.404648  2791.465576  ...   \n",
       "6449  393.947174  2771.234375 -196.037186  171.085327  2796.786621  ...   \n",
       "\n",
       "             f38          f39         f40         f41          f42  \\\n",
       "0     -114.83284  2771.922119  -78.613121 -542.027649  2771.436035   \n",
       "1    -115.326927  2772.170166  -77.628181 -544.114624  2772.243164   \n",
       "2    -115.031052  2772.760986   -76.57428 -543.925232  2773.098633   \n",
       "3    -114.668465  2772.653076  -75.057556  -544.48761  2775.745117   \n",
       "4    -114.363319   2772.71167  -74.918259 -544.191223  2775.963623   \n",
       "...          ...          ...         ...         ...          ...   \n",
       "6445  -62.636711  2768.670898  -117.46299 -495.449005  2783.337891   \n",
       "6446  -62.636711  2768.670898  -117.46299 -495.449005  2783.337891   \n",
       "6447  -62.891205  2767.439941  -114.05262  -498.39682  2785.745605   \n",
       "6448  -62.891205  2767.439941  -114.05262  -498.39682  2785.745605   \n",
       "6449  -61.606247  2769.630859 -115.142174 -498.411865  2786.321045   \n",
       "\n",
       "             f43         f44          f45 Action Human  \n",
       "0      -18.19173 -930.296204  2827.437988    1.0   1.0  \n",
       "1     -16.370182 -935.252625  2825.971436    1.0   1.0  \n",
       "2     -16.996519 -935.505066  2828.508057    1.0   1.0  \n",
       "3      -16.88364  -937.05603  2833.645752    1.0   1.0  \n",
       "4     -16.241182   -935.5224  2832.526611    1.0   1.0  \n",
       "...          ...         ...          ...    ...   ...  \n",
       "6445 -110.195564 -921.249329  2863.574463    9.0  10.0  \n",
       "6446 -110.195564 -921.249329  2863.574463    9.0  10.0  \n",
       "6447  -107.40934 -923.218323  2864.661865    9.0  10.0  \n",
       "6448  -107.40934 -923.218323  2864.661865    9.0  10.0  \n",
       "6449 -106.461594 -922.787598  2865.870117    9.0  10.0  \n",
       "\n",
       "[6450 rows x 48 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([215, 3, 15, 30])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxJoint = torch.max(dataset)\n",
    "minJoint = torch.min(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = (dataset - minJoint) / (maxJoint - minJoint)\n",
    "dataset = dataset - 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self,imgs,labels):\n",
    "        self.imgs = imgs\n",
    "        self.labels = labels\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.imgs[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset(dataset, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_size=43,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.input = nn.Sequential(\n",
    "            nn.Conv2d(4, 64, 3, 1, 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True))\n",
    "        self.embed = nn.Embedding(10 , 15 * 30)\n",
    "        self.hiddenLayers = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, 3, 1, 1),\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Conv2d(128,256,3,1,1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True)    \n",
    "        )\n",
    "        self.fc = nn.Linear(115200, 128)\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Linear(128,1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x, label):\n",
    "        label_embed = self.embed(label)\n",
    "        label_embed = label_embed.view(label_embed.size(0),1,15,30)\n",
    "        finalInput = torch.cat([x, label_embed], dim=1)\n",
    "        finalInput = self.input(finalInput)\n",
    "        finalInput = self.hiddenLayers(finalInput)\n",
    "        finalInput = finalInput.view(finalInput.size(0),-1)\n",
    "        finalInput = self.fc(finalInput)\n",
    "        finalInput = self.output(finalInput)\n",
    "        return finalInput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(10, 50)\n",
    "        self.input = nn.Sequential(\n",
    "            nn.ConvTranspose2d(150, 512, 4, 1, 0),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.hiddenlayers = nn.Sequential(\n",
    "            nn.ConvTranspose2d(512, 256, 4, 2, 1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(), \n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),  \n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),         \n",
    "            nn.ConvTranspose2d(64, 16, 4 , 2, 1) \n",
    "        )\n",
    "        self.layer = nn.Linear(65536, 1350)\n",
    "        self.output = nn.Tanh()\n",
    "    def forward(self,x, label):\n",
    "        labelEmb = self.embed(label)\n",
    "        labelEmb = labelEmb.view(labelEmb.size(0), 50, 1, 1)\n",
    "        finalInput = torch.cat([x, labelEmb], dim = 1)\n",
    "        finalInput = self.input(finalInput)\n",
    "        finalInput = self.hiddenlayers(finalInput)\n",
    "        finalInput = finalInput.view(finalInput.size(0),-1)\n",
    "        finalInput = self.layer(finalInput)\n",
    "        \n",
    "        finalInput = finalInput.view(finalInput.size(0), 3, 15, 30)\n",
    "        return self.output(finalInput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator(\n",
      "  (input): Sequential(\n",
      "    (0): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (embed): Embedding(10, 450)\n",
      "  (hiddenLayers): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (fc): Linear(in_features=115200, out_features=128, bias=True)\n",
      "  (output): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=1, bias=True)\n",
      "    (1): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(Discriminator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Models\n",
    "'''\n",
    "generator = Generator().to(device)\n",
    "discriminator = Discriminator().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Losses\n",
    "'''\n",
    "adversarial_loss = nn.BCELoss()\n",
    "adversarial_loss = adversarial_loss.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Optimizers\n",
    "'''\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(),lr=0.00001, betas=(0.5, 0.999) )\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(),lr=0.00001, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "\n",
    "epochs = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 50/2000 [00:27<16:12,  2.01it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gLoss ==> 0.7957\n",
      "dLoss ==> 1.2767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 100/2000 [00:52<15:52,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gLoss ==> 1.9914\n",
      "dLoss ==> 0.4174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 150/2000 [01:17<15:26,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gLoss ==> 0.8247\n",
      "dLoss ==> 1.2126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 200/2000 [01:43<15:01,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gLoss ==> 1.1234\n",
      "dLoss ==> 1.1835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 250/2000 [02:08<14:39,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gLoss ==> 0.7528\n",
      "dLoss ==> 0.9553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 300/2000 [02:33<14:12,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gLoss ==> 1.3057\n",
      "dLoss ==> 0.7658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 350/2000 [02:58<13:46,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gLoss ==> 0.9932\n",
      "dLoss ==> 0.8526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 400/2000 [03:23<13:21,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gLoss ==> 0.9978\n",
      "dLoss ==> 1.2569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▎       | 450/2000 [03:48<12:58,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gLoss ==> 0.4739\n",
      "dLoss ==> 1.2319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 500/2000 [04:13<12:31,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gLoss ==> 2.384\n",
      "dLoss ==> 0.6363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 550/2000 [04:38<12:05,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gLoss ==> 1.6827\n",
      "dLoss ==> 0.4583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 600/2000 [05:03<11:41,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gLoss ==> 1.4332\n",
      "dLoss ==> 0.7121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▎      | 650/2000 [05:28<11:15,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gLoss ==> 0.8274\n",
      "dLoss ==> 0.8644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 700/2000 [05:53<10:50,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gLoss ==> 1.0978\n",
      "dLoss ==> 0.7571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 750/2000 [06:18<10:26,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gLoss ==> 2.0764\n",
      "dLoss ==> 1.1531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 800/2000 [06:43<10:03,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gLoss ==> 0.2035\n",
      "dLoss ==> 1.9204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▎     | 850/2000 [07:09<09:40,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gLoss ==> 2.033\n",
      "dLoss ==> 0.6071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 900/2000 [07:34<09:13,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gLoss ==> 0.1673\n",
      "dLoss ==> 2.0145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 950/2000 [07:59<08:48,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gLoss ==> 1.8727\n",
      "dLoss ==> 1.2848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1000/2000 [08:24<08:23,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gLoss ==> 0.6504\n",
      "dLoss ==> 1.112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▎    | 1050/2000 [08:49<07:57,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gLoss ==> 3.423\n",
      "dLoss ==> 0.5106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 1100/2000 [09:15<07:39,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gLoss ==> 1.8169\n",
      "dLoss ==> 0.3439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▊    | 1150/2000 [09:40<07:08,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gLoss ==> 2.411\n",
      "dLoss ==> 0.642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 1200/2000 [10:05<06:41,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gLoss ==> 3.2668\n",
      "dLoss ==> 0.2515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 1250/2000 [10:31<06:23,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gLoss ==> 0.4548\n",
      "dLoss ==> 1.2897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 1300/2000 [10:56<05:51,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gLoss ==> 7.3323\n",
      "dLoss ==> 0.3913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 1350/2000 [11:21<05:28,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gLoss ==> 2.8706\n",
      "dLoss ==> 0.9068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 1400/2000 [11:46<05:01,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gLoss ==> 1.8672\n",
      "dLoss ==> 0.9766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▎  | 1450/2000 [12:11<04:37,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gLoss ==> 0.6934\n",
      "dLoss ==> 0.9957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 1500/2000 [12:37<04:10,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gLoss ==> 1.3881\n",
      "dLoss ==> 0.7074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 1550/2000 [13:02<03:47,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gLoss ==> 0.7196\n",
      "dLoss ==> 0.9391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 1600/2000 [13:27<03:20,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gLoss ==> 5.8734\n",
      "dLoss ==> 0.1637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▎ | 1650/2000 [13:52<02:55,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gLoss ==> 2.797\n",
      "dLoss ==> 0.4518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 1700/2000 [14:17<02:30,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gLoss ==> 1.229\n",
      "dLoss ==> 0.9842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 1750/2000 [14:42<02:06,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gLoss ==> 2.694\n",
      "dLoss ==> 0.9764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 1800/2000 [15:07<01:40,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gLoss ==> 0.8193\n",
      "dLoss ==> 0.8153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▎| 1850/2000 [15:33<01:15,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gLoss ==> 0.6797\n",
      "dLoss ==> 1.2242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 1900/2000 [15:58<00:50,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gLoss ==> 3.0017\n",
      "dLoss ==> 0.5676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 1950/2000 [16:23<00:25,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gLoss ==> 4.5211\n",
      "dLoss ==> 0.8446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [16:48<00:00,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gLoss ==> 2.8547\n",
      "dLoss ==> 0.8829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(epochs)):\n",
    "    gLoss = -1\n",
    "    dLoss = -1\n",
    "    f1score = float(\"inf\")\n",
    "    for index, (data, label) in enumerate(dataloader):\n",
    "\n",
    "        valid = Variable(Tensor(data.size(0), 1).fill_(1.0), requires_grad=False)\n",
    "        fake = Variable(Tensor(data.size(0), 1).fill_(0.0), requires_grad=False)\n",
    "\n",
    "        label = label.to(device)\n",
    "\n",
    "        real_imgs = Variable(data.type(Tensor))\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        z = Variable(Tensor(np.random.normal(0, 1, (data.shape[0], 100,1,1))))\n",
    "\n",
    "        gen_imgs = generator(z,label)\n",
    "\n",
    "        gen_imgs = gen_imgs.to(device)\n",
    "\n",
    "        g_loss = adversarial_loss(discriminator(gen_imgs,label), valid)\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        real_loss = adversarial_loss(discriminator(real_imgs,label), valid)\n",
    "        fake_loss = adversarial_loss(discriminator(gen_imgs.detach(),label), fake)\n",
    "\n",
    "        d_loss = (real_loss + fake_loss)\n",
    "\n",
    "        d_loss.backward()\n",
    "\n",
    "        optimizer_D.step()\n",
    "\n",
    "        gLoss = g_loss.item()\n",
    "        dLoss = d_loss.item()\n",
    "\n",
    "        f1Temp = -(gLoss * dLoss) / (gLoss + dLoss)\n",
    "        if f1Temp < f1score:\n",
    "            f1score = f1Temp\n",
    "            # torch.save(generator.state_dict(),'Models/generator.pth')\n",
    "    if (epoch+1)%50 == 0:\n",
    "        print('gLoss ==>',round(gLoss,4))\n",
    "        print(\"dLoss ==>\",round(dLoss,4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = generator(torch.randn(1, 100 , 1 , 1).to(device), torch.tensor([[1]]).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images + 0.5\n",
    "images = images * (maxJoint - minJoint)\n",
    "images = images + minJoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ -142.6859,   -53.8264,   -90.2791,  ...,   -49.0355,\n",
       "               9.2167,   -16.2069],\n",
       "          [ -219.1793,  -121.1600,  -113.7405,  ...,  -101.0005,\n",
       "             -48.0618,   -38.3032],\n",
       "          [ -154.7822,   -87.2634,   -46.0358,  ...,   -96.2675,\n",
       "             -37.9850,  -105.6514],\n",
       "          ...,\n",
       "          [   -8.6609,   -36.5859,     5.3986,  ...,    23.4196,\n",
       "             -37.5100,   100.0842],\n",
       "          [ -132.7388,   -35.0118,    29.1183,  ...,    -9.4705,\n",
       "              22.2977,   -21.3118],\n",
       "          [  133.1549,   107.9680,    41.0142,  ...,    87.5249,\n",
       "               4.0879,   -26.9163]],\n",
       "\n",
       "         [[  595.9054,   645.4562,   620.5333,  ...,   569.2972,\n",
       "             582.2992,   601.0936],\n",
       "          [  290.1754,   324.6591,   372.0774,  ...,   341.7295,\n",
       "             408.1864,   311.1992],\n",
       "          [  193.1750,   120.2783,   127.5544,  ...,   122.0002,\n",
       "             182.2882,   166.5129],\n",
       "          ...,\n",
       "          [ -124.2042,   -84.6405,  -100.6724,  ...,   -61.0945,\n",
       "             -48.3359,  -143.8334],\n",
       "          [ -546.8677,  -535.7531,  -516.5778,  ...,  -583.2812,\n",
       "            -515.5784,  -419.9995],\n",
       "          [ -981.8730,  -844.4279,  -898.7437,  ...,  -920.9191,\n",
       "           -1043.8928,  -871.7165]],\n",
       "\n",
       "         [[ 2906.9873,  2873.6152,  2895.2534,  ...,  2724.1714,\n",
       "            2720.7202,  2803.2822],\n",
       "          [ 2858.6162,  2987.5054,  2962.3081,  ...,  2842.8638,\n",
       "            2874.1499,  2905.2529],\n",
       "          [ 2834.9966,  2903.6133,  2921.5903,  ...,  2858.2812,\n",
       "            2904.1655,  2887.7534],\n",
       "          ...,\n",
       "          [ 2978.6245,  2905.9736,  2963.8159,  ...,  2835.5874,\n",
       "            2903.4302,  2911.0317],\n",
       "          [ 2918.8950,  3032.7046,  2983.1035,  ...,  2981.9292,\n",
       "            2962.9409,  2959.3105],\n",
       "          [ 3091.2671,  2890.3550,  3063.2051,  ...,  3060.0947,\n",
       "            2974.5459,  3115.5146]]]], device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "43d067841d78aac7fa29634787a4d238b2cfa1e9a088c54a4c88156792dfd315"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('machineLearning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
